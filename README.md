# MRD
Mutual Refinement Distillation for Multimodal Emotion Recognition: Interactive Learning and Reverse Curriculum for Complex Sample Classification
With the rapid advancement of speech emotion recognition, the transition
from unimodal to multimodal approaches has become inevitable. However,
multimodal methods introduce new challenges, particularly classification am-
biguity in complex samples when compared to unimodal approaches. To
address this, we propose a Mutual Refinement Distillation (MRD) method,
which incorporates three key components: (1) Modal Interaction Calibration,
enhancing classification accuracy for complex samples; (2) Interactive Learn-
ing Constraints, mitigating overfitting; and (3) Reverse Curriculum Learn-
ing, further improving model robustness. Experiments with the MELD and
IEMOCAP datasets demonstrate that our approach outperforms state-of-
the-art methods in emotion recognition, achieving a notable 6.07% improve-
ment over the baseline on IEMOCAP.
<img width="1282" height="702" alt="pipline" src="https://github.com/user-attachments/assets/c481e063-2deb-4a67-b227-eb4f1b827f25" />
