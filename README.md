# Mutual Refinement Distillation (MRD) for Multimodal Emotion Recognition

## Introduction

With the rapid advancement of speech emotion recognition, the transition from unimodal to multimodal approaches has become inevitable. However, multimodal methods introduce new challenges, especially classification ambiguity in complex samples compared to unimodal approaches.

**Mutual Refinement Distillation (MRD)** is a novel method designed to address these difficulties by leveraging interactive learning and curriculum strategies for better multimodal emotion recognition.

## Key Features

MRD integrates three major components:

1. **Modal Interaction Calibration**  
   - Enhances the classification accuracy for complex samples by calibrating interactions between modalities.

2. **Interactive Learning Constraints**  
   - Mitigates overfitting through effective interactive learning constraints.

3. **Reverse Curriculum Learning**  
   - Improves model robustness by reversing the traditional curriculum learning order, focusing on more complex samples earlier.

## Pipeline

![Pipeline](https://github.com/user-attachments/assets/c481e063-2deb-4a67-b227-eb4f1b827f25)

## Results

MRD has been evaluated on the following benchmarks:
- **MELD**
- **IEMOCAP**

**Highlights:**
- Outperforms state-of-the-art methods in emotion recognition.
- Achieves a notable **6.07% improvement over the baseline on IEMOCAP**.

## Usage

Coming soon.
